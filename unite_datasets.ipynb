{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "pwd = os.getcwd()\n",
    "# load ravdess.npy , savee.npy and tess.npy\n",
    "ravdess_data = np.load('ravdess.npy')\n",
    "savee_data = np.load('savee.npy') \n",
    "tess_data = np.load('tess.npy')\n",
    "crema_data = np.load('crema.npy')\n",
    "\n",
    "# ravdess_data.shape, savee_data.shape, tess_data.shape\n",
    "all_data = np.vstack((ravdess_data, savee_data, tess_data, crema_data))\n",
    "df = pd.DataFrame(all_data, columns=['label', 'gender', 'pathname', 'filename'])\n",
    "df.head(), df.shape\n",
    "\n",
    "# save all data into npy file\n",
    "# np.save(\"all_datasets.npy\", df)\n",
    "def plot_spec(y, sr, hop_size, y_axis):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    librosa.display.specshow(y, sr=sr, hop_length=hop_size, x_axis='time', y_axis= y_axis)\n",
    "    plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load wav files using the 'pathname' and 'filename' columns of all_data with librosa\n",
    "frame_size = 4096  # in samples\n",
    "hop_size = 1024  # in samples\n",
    "temporal_chunk_size = 20  # number of temporal bins per sample\n",
    "mel_bands = 128  # number of mel bands\n",
    "silence_threshold = 40  # in  relative to peak dB\n",
    "in_dB = True  # convert to dB\n",
    "mfcc_coefficients = 40  # number of MFCC coefficients\n",
    "\n",
    "# total temporal bins is total_samples/hop_size\n",
    "\n",
    "data = []\n",
    "\n",
    "for sample_index in range(df.shape[0]):\n",
    "    stft_temporal_chunks = []\n",
    "\n",
    "    pathname = df['pathname'][sample_index]\n",
    "    filename = df['filename'][sample_index]\n",
    "\n",
    "    wav, sr = librosa.load(pwd + pathname + filename)\n",
    "    trimmed_wav, _ = librosa.effects.trim(wav, top_db=silence_threshold)\n",
    "\n",
    "    if sr != 22050:\n",
    "        raise ValueError(\"Sample rate is not 22050Hz\")\n",
    "\n",
    "    # extract audio features for the audio file\n",
    "    S_audio = librosa.stft(trimmed_wav, n_fft=frame_size, hop_length=hop_size)\n",
    "    y_audio = np.abs(S_audio)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        S=y_audio, sr=sr, n_fft=frame_size, hop_length=hop_size, n_mels=mel_bands)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(mel_spec), sr=sr, n_mfcc=mfcc_coefficients)\n",
    "\n",
    "\n",
    "    # librosa.display.specshow(\n",
    "    #     _y[:temporal_chunk_size].T, sr=sr, hop_length=hop_size, x_axis='time', y_axis='log')\n",
    "    # plt.show()\n",
    "\n",
    "    # extract the mel spectrogram\n",
    "\n",
    "    if in_dB:\n",
    "        y_audio = librosa.power_to_db(y_audio, ref=np.max)\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        # mfccs = librosa.power_to_db(mfccs)\n",
    "        \n",
    "    # split y into chunks of size temporal_chunk_size.\n",
    "    _y = (y_audio).T\n",
    "    _mel_spec = (mel_spec).T\n",
    "    _mfccs = (mfccs).T\n",
    "\n",
    "\n",
    "    split_indices = np.unique([(i, len(_y) - temporal_chunk_size)[int(\n",
    "        i + temporal_chunk_size >= len(_y))]for i in range(0, len(_y), temporal_chunk_size)])\n",
    "\n",
    "    # to include mel-spec add `_mel_spec[i:i+temporal_chunk_size].T` in the list\n",
    "    [ stft_temporal_chunks.append([ \n",
    "        _y[i:i+temporal_chunk_size].T, \n",
    "        _mel_spec[i:i+temporal_chunk_size].T,\n",
    "        _mfccs[i:i+temporal_chunk_size].T ,\n",
    "        df['gender'][sample_index], \n",
    "        df['label'][sample_index]])\n",
    "     for i in split_indices ]\n",
    "\n",
    "    # librosa.display.waveshow(trimmed_wav, sr=sr)\n",
    "\n",
    "    [data.append(c) for c in stft_temporal_chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.array(data) \n",
    "processed_dataset = pd.DataFrame(data, columns=['stft_data', 'mel_data', 'mfcc_data', 'gender', 'label'])\n",
    "\n",
    "#plot the stft at index 0 of processed_dataset\n",
    "# stfts = processed_dataset['mfcc_data'][:10]\n",
    "# for stft in stfts:\n",
    "#     # print(stft[0].shape)\n",
    "#     plot_spec(stft, hop_size=hop_size, sr=sr, y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"processed_dataset.npy\",  processed_dataset)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39d7a255d4176126bb60d58490ff3164cc3b659c87e283a77bc5e59f8812299c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
