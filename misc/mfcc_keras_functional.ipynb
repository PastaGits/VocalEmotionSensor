{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d3f7f5-7af4-4e13-8f85-a524eda1256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from disk...\n",
      "data loaded! calculating mfcc delta features for data...\n",
      "(24133, 39, 50)\n",
      "done.\n",
      "(16169, 39, 50), (7964, 39, 50), (16169, 1), (7964, 1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file = h5py.File('E:/dataset_6ms.h5', 'r')\n",
    "\n",
    "gender_labels = file['gender'][...].squeeze().astype(str)\n",
    "print('loading data from disk...')\n",
    "\n",
    "# female_indexes =  np.where(gender_labels == 'female')\n",
    "indexes =  np.where(gender_labels == 'female')\n",
    "y = file['label'][indexes]\n",
    "X = file['mfcc'][indexes]\n",
    "print('data loaded! calculating mfcc delta features for data...')\n",
    "\n",
    "# print(f\" {X.shape}, {y.shape}\")\n",
    "\n",
    "# extract delta and double delta features using librosa\n",
    "X_deltas = np.zeros((X.shape[0], X.shape[1]*3, X.shape[2]))\n",
    "print(X_deltas.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    X_delta = librosa.feature.delta(X[i])\n",
    "    X_delta2 = librosa.feature.delta(X[i], order=2)\n",
    "    # np.vstack all the X, X_delta and X_delta2 \n",
    "    new_features = np.vstack([X[i], X_delta, X_delta2])\n",
    "    X_deltas[i] = new_features\n",
    "    # print(X_deltas[i].shape)\n",
    "\n",
    "print(\"done.\")\n",
    "print(\"creating test train split...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_deltas, y, test_size=0.33, random_state=32)\n",
    "print(f\"{X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047ded05-455b-4685-99c5-383ba3e82b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 50)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (39, 50, 64) and (39, 50, 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Julio\\Documents\\GitHub\\VocalEmotionSensor\\misc\\mfcc_keras_functional.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=69'>70</a>\u001b[0m x \u001b[39m=\u001b[39m Permute((\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m))(x_transpose)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=71'>72</a>\u001b[0m \u001b[39m# 1st residual block\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=72'>73</a>\u001b[0m x \u001b[39m=\u001b[39m res_block(x, \u001b[39m64\u001b[39;49m, (\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=73'>74</a>\u001b[0m \u001b[39m# 2nd residual block\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=74'>75</a>\u001b[0m x \u001b[39m=\u001b[39m res_block(x, \u001b[39m128\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\Julio\\Documents\\GitHub\\VocalEmotionSensor\\misc\\mfcc_keras_functional.ipynb Cell 2'\u001b[0m in \u001b[0;36mres_block\u001b[1;34m(x_in, channels_in, kernel, downsample)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=53'>54</a>\u001b[0m \u001b[39mif\u001b[39;00m downsample:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=54'>55</a>\u001b[0m     \u001b[39m# match x_in to shape of x using kernelsize 1 convolution\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=55'>56</a>\u001b[0m     x_in \u001b[39m=\u001b[39m Conv2D(kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=56'>57</a>\u001b[0m                   filters\u001b[39m=\u001b[39mchannels_in, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m)(x_in)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=57'>58</a>\u001b[0m res \u001b[39m=\u001b[39m Add()([x, x_in])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Julio/Documents/GitHub/VocalEmotionSensor/misc/mfcc_keras_functional.ipynb#ch0000001?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\Julio\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Julio\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\layers\\merge.py:78\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[1;34m(self, shape1, shape2)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=75'>76</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=76'>77</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=77'>78</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=78'>79</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mInputs have incompatible shapes. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=79'>80</a>\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mReceived shapes \u001b[39m\u001b[39m{\u001b[39;00mshape1\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mshape2\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=80'>81</a>\u001b[0m     output_shape\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m     <a href='file:///c%3A/Users/Julio/AppData/Local/Programs/Python/Python39/lib/site-packages/keras/layers/merge.py?line=81'>82</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(output_shape)\n",
      "\u001b[1;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (39, 50, 64) and (39, 50, 39)"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Add\n",
    "from keras.layers import Flatten, Dropout, LeakyReLU, Permute, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, AveragePooling2D\n",
    "from keras.layers import Conv1D, Layer, Input, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import adam_v2\n",
    "import tensorflow as tf\n",
    "# import rms prop from keras\n",
    "\n",
    "\n",
    "# class Residual(Layer):\n",
    "#     def __init__(self, channels_in, kernel, **kwargs):\n",
    "#         super(Residual, self).__init__(**kwargs)\n",
    "#         self.channels_in = channels_in\n",
    "#         self.kernel = kernel\n",
    "\n",
    "#     @tf.function\n",
    "#     def call(self, x):\n",
    "#         # the residual block using Keras functional API\n",
    "#         first_layer = Activation(\"linear\", trainable=False)(x)\n",
    "#         x = Conv2D(self.channels_in,\n",
    "#                    self.kernel,\n",
    "#                    padding=\"same\")(first_layer)\n",
    "#         x = LeakyReLU(alpha=0.08)(x)\n",
    "#         x = Conv2D(self.channels_in,\n",
    "#                    self.kernel,\n",
    "#                    padding=\"same\")(x)\n",
    "#         residual = Add()([x, first_layer])\n",
    "#         x = LeakyReLU(alpha=0.08)(residual)\n",
    "#         return x\n",
    "\n",
    "#     @tf.function\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return input_shape\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "opt = adam_v2.Adam(learning_rate=0.0008)\n",
    "\n",
    "\n",
    "def res_block(x_in, channels_in, kernel: tuple, downsample=False):\n",
    "    x = BatchNormalization()(x_in)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(channels_in, kernel, padding='same',\n",
    "               strides= ((1, 2)[int(downsample)]))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(channels_in, kernel, padding='same')(x)\n",
    "    if downsample:\n",
    "        # match x_in to shape of x using kernelsize 1 convolution\n",
    "        x_in = Conv2D(kernel_size=1, strides=2,\n",
    "                      filters=channels_in, padding='same')(x_in)\n",
    "    res = Add()([x, x_in])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "feature_shape = X_train[0].shape\n",
    "print(feature_shape)\n",
    "\n",
    "inputs = Input(shape=feature_shape)\n",
    "initial_layer = Reshape((feature_shape[0], feature_shape[1], 1))(inputs)\n",
    "x_transpose = Permute((2, 1, 3))(initial_layer)\n",
    "x_transpose = Dense(39, activation=\"relu\")(x_transpose)\n",
    "x = Permute((2, 1, 3))(x_transpose)\n",
    "\n",
    "# 1st residual block\n",
    "x = Conv2D()\n",
    "x = res_block(x, 64, (3, 3))\n",
    "# 2nd residual block\n",
    "x = res_block(x, 128, (3, 3))\n",
    "\n",
    "# flatten the output and add a dense layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "out = Dense(6)(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt, metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ae786-ee7a-40ec-93df-8804c98f8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size=700, epochs=200,validation_data=(X_test, y_test), shuffle=True, callbacks=[es], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfbba3-42d1-434c-a1d9-814c38da5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model history\n",
    "# cnnhistory.model.save('cnn_66.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db10ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.save('my_model_984.h5')\n",
    "acc = cnnhistory.history['sparse_categorical_accuracy']\n",
    "val_acc = cnnhistory.history['val_sparse_categorical_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "loss = cnnhistory.history['loss']\n",
    "val_loss = cnnhistory.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5), dpi=80)\n",
    "\n",
    "ax[0].plot(epochs, acc,'--r', label='Training Acc')\n",
    "ax[0].plot(epochs, val_acc, '-b', label='Validation Acc')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Training and Validation accuracy')\n",
    "\n",
    "ax[1].plot(epochs, loss,'--r' ,label='Training Loss')\n",
    "ax[1].plot(epochs, val_loss, '-g',label='Validation Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Training and Validation Loss')\n",
    "\n",
    "print(\"Model Accuracy Metrics: \")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "labels = ['neutral','calm','happy','sad','angry','fearful']\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "# print(y_pred.argmax(axis=1))\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax =ConfusionMatrixDisplay.from_predictions(y_pred, y_test, display_labels=labels)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87291ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353fd8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "old = keras.models.load_model('cnn_63.h5')\n",
    "old.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70fa698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e9a847315198e1db6c3e64fe9ef1c8f4cc1666ddba368d2a78c3257c3b63773"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
