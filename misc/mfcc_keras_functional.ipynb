{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d3f7f5-7af4-4e13-8f85-a524eda1256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from disk...\n",
      "data loaded! calculating mfcc delta features for data...\n",
      "(24133, 39, 50)\n",
      "done.\n",
      "creating test train split...\n",
      "(16169, 39, 50), (7964, 39, 50), (16169, 1), (7964, 1)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "file = h5py.File('E:/dataset_6ms.h5', 'r')\n",
    "\n",
    "gender_labels = file['gender'][...].squeeze().astype(str)\n",
    "print('loading data from disk...')\n",
    "\n",
    "# female_indexes =  np.where(gender_labels == 'female')\n",
    "indexes =  np.where(gender_labels == 'female')\n",
    "y = file['label'][indexes]\n",
    "X = file['mfcc'][indexes]\n",
    "print('data loaded! calculating mfcc delta features for data...')\n",
    "\n",
    "# print(f\" {X.shape}, {y.shape}\")\n",
    "\n",
    "# extract delta and double delta features using librosa\n",
    "X_deltas = np.zeros((X.shape[0], X.shape[1]*3, X.shape[2]))\n",
    "print(X_deltas.shape)\n",
    "for i in range(X.shape[0]):\n",
    "    X_delta = librosa.feature.delta(X[i])\n",
    "    X_delta2 = librosa.feature.delta(X[i], order=2)\n",
    "    # np.vstack all the X, X_delta and X_delta2 \n",
    "    new_features = np.vstack([X[i], X_delta, X_delta2])\n",
    "    X_deltas[i] = new_features\n",
    "    # print(X_deltas[i].shape)\n",
    "\n",
    "print(\"done.\")\n",
    "print(\"creating test train split...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_deltas, y, test_size=0.33, random_state=32)\n",
    "print(f\"{X_train.shape}, {X_test.shape}, {y_train.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047ded05-455b-4685-99c5-383ba3e82b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 50)\n",
      "(None, 7, 5, 128) (None, 7, 5, 128)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 39, 50)]     0           []                               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 39, 50, 1)    0           ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " permute_1 (Permute)            (None, 50, 39, 1)    0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 50, 39, 1)   4           ['permute_1[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 50, 39, 32)   64          ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 20, 32)   15392       ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 25, 20, 32)  128         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 25, 20, 32)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 25, 20, 32)   15392       ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 25, 20, 32)  128         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 25, 20, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 25, 20, 32)   1056        ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 25, 20, 128)  256         ['permute_1[0][0]']              \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 25, 20, 32)   0           ['leaky_re_lu_13[0][0]',         \n",
      "                                                                  'conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 25, 20, 128)  512        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 25, 20, 32)   0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)     (None, 25, 20, 128)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 25, 20, 64)   2112        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 25, 20, 128)  16512       ['leaky_re_lu_18[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 13, 10, 64)   61504       ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 25, 20, 128)  512        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 13, 10, 64)  256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)     (None, 25, 20, 128)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 25, 20, 128)  256         ['permute_1[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 13, 10, 64)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 25, 20, 128)  0           ['leaky_re_lu_19[0][0]',         \n",
      "                                                                  'conv2d_35[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 13, 10, 64)   61504       ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 13, 10, 128)  16512       ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 13, 10, 64)  256         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 13, 10, 128)  512        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 13, 10, 64)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 13, 10, 64)   4160        ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)     (None, 13, 10, 128)  0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 13, 10, 64)   0           ['leaky_re_lu_15[0][0]',         \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 13, 10, 128)  16512       ['leaky_re_lu_20[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 13, 10, 64)   0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 13, 10, 128)  512        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 13, 10, 128)  8320        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)     (None, 13, 10, 128)  0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 13, 10, 128)  16512       ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 7, 5, 128)    245888      ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 13, 10, 128)  0           ['leaky_re_lu_21[0][0]',         \n",
      "                                                                  'conv2d_38[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 7, 5, 128)   512         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 7, 5, 128)    16512       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)     (None, 7, 5, 128)    0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 7, 5, 128)   512         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 7, 5, 128)    245888      ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)     (None, 7, 5, 128)    0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 7, 5, 128)   512         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 7, 5, 128)    16512       ['leaky_re_lu_22[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)     (None, 7, 5, 128)    0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 7, 5, 128)    16512       ['conv2d_29[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 7, 5, 128)   512         ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 7, 5, 128)    0           ['leaky_re_lu_17[0][0]',         \n",
      "                                                                  'conv2d_32[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)     (None, 7, 5, 128)    0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 7, 5, 128)    16512       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 7, 5, 128)    0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 7, 5, 128)    0           ['leaky_re_lu_23[0][0]',         \n",
      "                                                                  'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 7, 5, 128)    0           ['dropout_6[0][0]',              \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 128)         0           ['add_14[0][0]']                 \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 128)         0           ['add_14[0][0]']                 \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 128)          0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 128)          0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          16512       ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6)            390         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 823,914\n",
      "Trainable params: 821,480\n",
      "Non-trainable params: 2,434\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D, Add\n",
    "from keras.layers import Flatten, Dropout, LeakyReLU, Permute, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, AveragePooling2D\n",
    "from keras.layers import Conv1D, Layer, Input, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers import adam_v2\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "# import rms prop from keras\n",
    "\n",
    "timestr = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "name = 'mfcc_resnet-'+timestr  # or 'cifar-10_plain_net_30-'+timestr\n",
    "checkpoint_path = \"checkpoints/\"+name+\"/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "cp = cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=0\n",
    ")\n",
    "opt = adam_v2.Adam()\n",
    "\n",
    "\n",
    "def res_block(x_in, channels_in, kernel: tuple, downsample=False):\n",
    "    x = x_in\n",
    "    x = Conv2D(channels_in, kernel, padding='same',\n",
    "               strides=((1, 2)[int(downsample)]))(x_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.08)(x)\n",
    "\n",
    "    x = Conv2D(channels_in, kernel, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.08)(x)\n",
    "    if downsample:\n",
    "        # match x_in to shape of x\n",
    "        x_in = Conv2D(kernel_size=1, strides=2,\n",
    "                      filters=channels_in, padding='same')(x_in)\n",
    "    res = Add()([x, x_in])\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "feature_shape = X_train[0].shape\n",
    "print(feature_shape)\n",
    "\n",
    "inputs = Input(shape=feature_shape)\n",
    "initial_layer = Reshape((feature_shape[0], feature_shape[1], 1))(inputs)\n",
    "x_transpose = Permute((2, 1, 3))(initial_layer)\n",
    "# x = initial_layer\n",
    "x = x_transpose\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "# 1st residual block\n",
    "x = Conv2D(32, (1, 1),  activation='linear')(x)\n",
    "x = res_block(x , 32, (3, 5), True)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 2nd residual block\n",
    "x = Conv2D(64, (1, 1),  activation='linear')(x)\n",
    "x = res_block(x, 64, (3, 5), True)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 3rd residual block\n",
    "x = Conv2D(128, (1, 1))(x)\n",
    "x = res_block(x, 128, (3, 5), True)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x_inital = res_block(x_transpose , 128, (1, 1), True)\n",
    "x_inital = res_block(x_inital , 128, (1, 1), True)\n",
    "x_inital = res_block(x_inital , 128, (1, 1), True)\n",
    "\n",
    "# # another residual connection\n",
    "print (x_inital.shape, x.shape)\n",
    "x = Add()([x, x_inital])\n",
    "\n",
    "x_avg = GlobalAveragePooling2D()(x)\n",
    "x_global = GlobalMaxPooling2D()(x)\n",
    "\n",
    "x = Add()([x_avg, x_global])\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "out = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt, metrics=['sparse_categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e4ae786-ee7a-40ec-93df-8804c98f8840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 17s 642ms/step - loss: 6.1041 - sparse_categorical_accuracy: 0.2173 - val_loss: 3.1489 - val_sparse_categorical_accuracy: 0.1813\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 1.6433 - sparse_categorical_accuracy: 0.2962 - val_loss: 3.1105 - val_sparse_categorical_accuracy: 0.2206\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 1.4260 - sparse_categorical_accuracy: 0.3628 - val_loss: 2.6686 - val_sparse_categorical_accuracy: 0.2266\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 1.3706 - sparse_categorical_accuracy: 0.3833 - val_loss: 2.5708 - val_sparse_categorical_accuracy: 0.2366\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 9s 547ms/step - loss: 1.3092 - sparse_categorical_accuracy: 0.4275 - val_loss: 2.2914 - val_sparse_categorical_accuracy: 0.2652\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 1.2620 - sparse_categorical_accuracy: 0.4486 - val_loss: 2.6566 - val_sparse_categorical_accuracy: 0.2521\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 1.1910 - sparse_categorical_accuracy: 0.4826 - val_loss: 1.8131 - val_sparse_categorical_accuracy: 0.2951\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 1.1529 - sparse_categorical_accuracy: 0.5068 - val_loss: 2.0627 - val_sparse_categorical_accuracy: 0.3211\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 1.1040 - sparse_categorical_accuracy: 0.5279 - val_loss: 1.6362 - val_sparse_categorical_accuracy: 0.3403\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 8s 499ms/step - loss: 1.0553 - sparse_categorical_accuracy: 0.5507 - val_loss: 1.5683 - val_sparse_categorical_accuracy: 0.3720\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 9s 518ms/step - loss: 1.0425 - sparse_categorical_accuracy: 0.5503 - val_loss: 2.0951 - val_sparse_categorical_accuracy: 0.3589\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 1.0390 - sparse_categorical_accuracy: 0.5538 - val_loss: 1.4104 - val_sparse_categorical_accuracy: 0.3813\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 9s 513ms/step - loss: 1.0077 - sparse_categorical_accuracy: 0.5714 - val_loss: 1.9322 - val_sparse_categorical_accuracy: 0.3772\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 9s 525ms/step - loss: 0.9924 - sparse_categorical_accuracy: 0.5752 - val_loss: 1.3722 - val_sparse_categorical_accuracy: 0.4543\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 9s 511ms/step - loss: 0.9584 - sparse_categorical_accuracy: 0.5870 - val_loss: 1.3060 - val_sparse_categorical_accuracy: 0.4620\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 0.9456 - sparse_categorical_accuracy: 0.5929 - val_loss: 1.5607 - val_sparse_categorical_accuracy: 0.4514\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.9565 - sparse_categorical_accuracy: 0.5862 - val_loss: 2.7937 - val_sparse_categorical_accuracy: 0.4561\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 9s 521ms/step - loss: 0.9289 - sparse_categorical_accuracy: 0.6013 - val_loss: 1.7238 - val_sparse_categorical_accuracy: 0.4723\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 0.9162 - sparse_categorical_accuracy: 0.6053 - val_loss: 2.0993 - val_sparse_categorical_accuracy: 0.4618\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 0.8982 - sparse_categorical_accuracy: 0.6164 - val_loss: 1.0418 - val_sparse_categorical_accuracy: 0.5431\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.8900 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.9619 - val_sparse_categorical_accuracy: 0.5742\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 0.9071 - sparse_categorical_accuracy: 0.6128 - val_loss: 1.0951 - val_sparse_categorical_accuracy: 0.5554\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.8779 - sparse_categorical_accuracy: 0.6251 - val_loss: 1.2736 - val_sparse_categorical_accuracy: 0.5380\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.8728 - sparse_categorical_accuracy: 0.6266 - val_loss: 1.3881 - val_sparse_categorical_accuracy: 0.5193\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 9s 514ms/step - loss: 0.8560 - sparse_categorical_accuracy: 0.6341 - val_loss: 1.0161 - val_sparse_categorical_accuracy: 0.5869\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 9s 512ms/step - loss: 0.8530 - sparse_categorical_accuracy: 0.6381 - val_loss: 0.8620 - val_sparse_categorical_accuracy: 0.6322\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 9s 531ms/step - loss: 0.8574 - sparse_categorical_accuracy: 0.6321 - val_loss: 0.9132 - val_sparse_categorical_accuracy: 0.6129\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 9s 522ms/step - loss: 0.8517 - sparse_categorical_accuracy: 0.6364 - val_loss: 1.2475 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 9s 504ms/step - loss: 0.8434 - sparse_categorical_accuracy: 0.6390 - val_loss: 0.9303 - val_sparse_categorical_accuracy: 0.6105\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 9s 527ms/step - loss: 0.8286 - sparse_categorical_accuracy: 0.6482 - val_loss: 0.9159 - val_sparse_categorical_accuracy: 0.6099\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 9s 517ms/step - loss: 0.8338 - sparse_categorical_accuracy: 0.6484 - val_loss: 0.8984 - val_sparse_categorical_accuracy: 0.6161\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 9s 520ms/step - loss: 0.8190 - sparse_categorical_accuracy: 0.6477 - val_loss: 0.9872 - val_sparse_categorical_accuracy: 0.5860\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 9s 517ms/step - loss: 0.8194 - sparse_categorical_accuracy: 0.6493 - val_loss: 1.0859 - val_sparse_categorical_accuracy: 0.5584\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 9s 524ms/step - loss: 0.8150 - sparse_categorical_accuracy: 0.6545 - val_loss: 0.8904 - val_sparse_categorical_accuracy: 0.6220\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 9s 516ms/step - loss: 0.8060 - sparse_categorical_accuracy: 0.6579 - val_loss: 0.8824 - val_sparse_categorical_accuracy: 0.6179\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 9s 507ms/step - loss: 0.8003 - sparse_categorical_accuracy: 0.6600 - val_loss: 0.9652 - val_sparse_categorical_accuracy: 0.5948\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 9s 529ms/step - loss: 0.8012 - sparse_categorical_accuracy: 0.6628 - val_loss: 0.9214 - val_sparse_categorical_accuracy: 0.6204\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.7890 - sparse_categorical_accuracy: 0.6669 - val_loss: 1.2329 - val_sparse_categorical_accuracy: 0.5325\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.7802 - sparse_categorical_accuracy: 0.6733 - val_loss: 0.8775 - val_sparse_categorical_accuracy: 0.6381\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.7926 - sparse_categorical_accuracy: 0.6635 - val_loss: 0.8940 - val_sparse_categorical_accuracy: 0.6114\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 9s 530ms/step - loss: 0.7860 - sparse_categorical_accuracy: 0.6687 - val_loss: 0.9620 - val_sparse_categorical_accuracy: 0.5976\n",
      "Epoch 41: early stopping\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_train, y_train, batch_size=1000, epochs=200,validation_data=(X_test, y_test), shuffle=True, callbacks=[es], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db10ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model.save('my_model_984.h5')\n",
    "acc = cnnhistory.history['sparse_categorical_accuracy']\n",
    "val_acc = cnnhistory.history['val_sparse_categorical_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "loss = cnnhistory.history['loss']\n",
    "val_loss = cnnhistory.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5), dpi=80)\n",
    "\n",
    "ax[0].plot(epochs, acc,'--r', label='Training Acc')\n",
    "ax[0].plot(epochs, val_acc, '-b', label='Validation Acc')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Training and Validation accuracy')\n",
    "\n",
    "ax[1].plot(epochs, loss,'--r' ,label='Training Loss')\n",
    "ax[1].plot(epochs, val_loss, '-g',label='Validation Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Training and Validation Loss')\n",
    "\n",
    "print(\"Model Accuracy Metrics: \")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "labels = ['neutral','calm','happy','sad','angry','fearful']\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "# print(y_pred.argmax(axis=1))\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "print(\"Model Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "ax = ConfusionMatrixDisplay.from_predictions(y_pred, y_test, display_labels=labels).plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "353fd8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_16 (Reshape)        (None, 39, 50, 1)         0         \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 39, 50, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 39, 50, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_71 (LeakyReLU)  (None, 39, 50, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 19, 25, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 19, 25, 32)        0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 19, 25, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_72 (LeakyReLU)  (None, 19, 25, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 10, 25, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 10, 25, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 10, 25, 64)        0         \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 10, 25, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_73 (LeakyReLU)  (None, 10, 25, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 5, 25, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 5, 25, 128)        0         \n",
      "                                                                 \n",
      " dropout_76 (Dropout)        (None, 5, 25, 128)        0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 16000)             0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 512)               8192512   \n",
      "                                                                 \n",
      " leaky_re_lu_74 (LeakyReLU)  (None, 512)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_77 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 6)                 390       \n",
      "                                                                 \n",
      " leaky_re_lu_75 (LeakyReLU)  (None, 6)                 0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 6)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,359,920\n",
      "Trainable params: 8,359,728\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "old = keras.models.load_model('cnn_63.h5')\n",
    "old.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9543172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "from keras.utils import vis_utils\n",
    "\n",
    "vis_utils.plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "\n",
    "# Image('model.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e9a847315198e1db6c3e64fe9ef1c8f4cc1666ddba368d2a78c3257c3b63773"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
