{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "pwd = os.getcwd()\n",
    "# load ravdess.npy , savee.npy and tess.npy\n",
    "ravdess_data = np.load(pwd+'/data/npy_files/ravdess.npy')\n",
    "savee_data = np.load(pwd+'/data/npy_files/savee.npy')\n",
    "tess_data = np.load(pwd+'/data/npy_files/tess.npy')\n",
    "crema_data = np.load(pwd+'/data/npy_files/crema.npy')\n",
    "\n",
    "all_data = np.vstack((ravdess_data, savee_data, tess_data, crema_data))\n",
    "df = pd.DataFrame(all_data, columns=[\n",
    "                  'label', 'gender', 'pathname', 'filename'])\n",
    "\n",
    "label_dict = { 'n': 0, 'c': 1, 'h': 2, 'sa': 3,\n",
    "               'a': 4, 'f': 5, 'd': 6, 'su': 7 }\n",
    "df['label'] = df['label'].map(label_dict)\n",
    "\n",
    "\n",
    "def plot_spec(y, sr, hop_size, y_axis):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    librosa.display.specshow(\n",
    "        y, sr=sr, hop_length=hop_size, x_axis='time', y_axis=y_axis)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "frame_size = 4096  # in samples\n",
    "hop_size = 256  # in samples\n",
    "temporal_chunk_size = 50  # number of temporal bins per sample\n",
    "mel_bands = 128  # number of mel bands\n",
    "silence_threshold = 40  # in  relative to peak dB\n",
    "in_dB = True  # convert to dB\n",
    "mfcc_coefficients = 12  # number of MFCC coefficients\n",
    "\n",
    "# total temporal bins is total_samples/hop_size\n",
    "data_cols = ['stft_data', 'mel_data', 'mfcc_data']\n",
    "\n",
    "f = h5py.File('dataset.h5', 'a')\n",
    "\n",
    "\n",
    "def add_to_dataset(temporal_chunks):\n",
    "    n_chunks = len(temporal_chunks)\n",
    "    new_stft_data = np.array([temporal_chunks[i][0] for i in range(n_chunks)])\n",
    "    new_mel_data = np.array([temporal_chunks[i][1] for i in range(n_chunks)])\n",
    "    new_mfcc_data = np.array([temporal_chunks[i][2] for i in range(n_chunks)])\n",
    "    new_gender_data = np.array([temporal_chunks[i][3]\n",
    "                               for i in range(n_chunks)]).reshape(n_chunks, 1).astype('|S6')\n",
    "    new_label_data = np.array([temporal_chunks[i][4]\n",
    "                              for i in range(n_chunks)]).reshape(n_chunks, 1)\n",
    "\n",
    "    # return\n",
    "    if len(f.keys()) == 0:\n",
    "        # create separate datasets for each col\n",
    "        f.create_dataset('stft', data=new_stft_data,\n",
    "                         compression=\"gzip\", chunks=True, maxshape=(None, new_stft_data.shape[1], temporal_chunk_size))\n",
    "        f.create_dataset('mel_spec', data=new_mel_data, compression=\"gzip\",\n",
    "                         chunks=True, maxshape=(None, mel_bands, temporal_chunk_size))\n",
    "        f.create_dataset('mfcc', data=new_mfcc_data,\n",
    "                         compression=\"gzip\", chunks=True, maxshape=(None, mfcc_coefficients, temporal_chunk_size))\n",
    "        f.create_dataset('gender', data=new_gender_data,\n",
    "                         compression=\"gzip\", chunks=True, maxshape=(None, 1))\n",
    "        f.create_dataset('label', data=new_label_data,\n",
    "                         compression=\"gzip\", chunks=True, maxshape=(None, 1))\n",
    "\n",
    "    f['stft'].resize((f['stft'].shape[0] + new_stft_data.shape[0]), axis=0)\n",
    "    f['stft'][-new_stft_data.shape[0]:] = new_stft_data\n",
    "\n",
    "    f['mel_spec'].resize(\n",
    "        (f['mel_spec'].shape[0] + new_mel_data.shape[0]), axis=0)\n",
    "    f['mel_spec'][-new_mel_data.shape[0]:] = new_mel_data\n",
    "\n",
    "    f['mfcc'].resize((f['mfcc'].shape[0] + new_mfcc_data.shape[0]), axis=0)\n",
    "    f['mfcc'][-new_mfcc_data.shape[0]:] = new_mfcc_data\n",
    "\n",
    "    f['gender'].resize(\n",
    "        (f['gender'].shape[0] + new_gender_data.shape[0]), axis=0)\n",
    "    f['gender'][-new_gender_data.shape[0]:] = new_gender_data\n",
    "\n",
    "    f['label'].resize((f['label'].shape[0] + new_label_data.shape[0]), axis=0)\n",
    "    f['label'][-new_label_data.shape[0]:] = new_label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_index in tqdm(range(df.shape[0])):\n",
    "    temporal_chunks = []\n",
    "\n",
    "    pathname = df['pathname'][sample_index]\n",
    "    filename = df['filename'][sample_index]\n",
    "\n",
    "    wav, sr = librosa.load(pwd + pathname + filename)\n",
    "    trimmed_wav, _ = librosa.effects.trim(wav, top_db=silence_threshold)\n",
    "\n",
    "    if sr != 22050:\n",
    "        raise ValueError(\"Sample rate is not 22050Hz\")\n",
    "\n",
    "    # extract audio features for the audio file\n",
    "    S_audio = librosa.stft(trimmed_wav, n_fft=frame_size, hop_length=hop_size)\n",
    "    y_audio = np.abs(S_audio)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        S=y_audio, sr=sr, n_fft=frame_size, hop_length=hop_size, n_mels=mel_bands)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(S=librosa.power_to_db(\n",
    "        mel_spec), sr=sr, n_mfcc=mfcc_coefficients)\n",
    "\n",
    "    if in_dB:\n",
    "        y_audio = librosa.power_to_db(y_audio, ref=np.max)\n",
    "        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # split y into chunks of size temporal_chunk_size.\n",
    "    _y = (y_audio).T\n",
    "    _mel_spec = (mel_spec).T\n",
    "    _mfccs = (mfccs).T\n",
    "\n",
    "    split_indices = np.unique([(i, len(_y) - temporal_chunk_size)[int(\n",
    "        i + temporal_chunk_size >= len(_y))]for i in range(0, len(_y), temporal_chunk_size)])\n",
    "\n",
    "    # to include mel-spec add `_mel_spec[i:i+temporal_chunk_size].T` in the list\n",
    "    [temporal_chunks.append([\n",
    "        np.array(_y[i:i+temporal_chunk_size].T, dtype=np.float32),\n",
    "        np.array(_mel_spec[i:i+temporal_chunk_size].T, dtype=np.float32),\n",
    "        np.array(_mfccs[i:i+temporal_chunk_size].T, dtype=np.float32),\n",
    "        df['gender'][sample_index],\n",
    "        df['label'][sample_index]])\n",
    "     for i in split_indices]\n",
    "\n",
    "    plot_spec(y=np.array(_mel_spec[0:0+temporal_chunk_size].T, dtype=np.float32),sr=sr, hop_size=hop_size,y_axis='mel')\n",
    "    add_to_dataset(temporal_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f.attrs['sample_rate'] = sr\n",
    "f.attrs['window_size'] = frame_size\n",
    "f.attrs['hop_size'] = hop_size\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e9a847315198e1db6c3e64fe9ef1c8f4cc1666ddba368d2a78c3257c3b63773"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
